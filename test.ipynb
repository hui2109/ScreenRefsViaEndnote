{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-22T05:08:13.094316800Z",
     "start_time": "2023-07-22T05:08:13.056113500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# 解析endnote导出的xml文档\n",
    "from lxml import etree\n",
    "path = './sources/source.xml'\n",
    "tree = etree.parse(path)\n",
    "findings = tree.xpath('//record')\n",
    "print(type(findings))\n",
    "a = findings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(<Element record at 0x1d80c0fffc0>, lxml.etree._Element)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, type(a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T14:06:13.498368300Z",
     "start_time": "2023-07-21T14:06:13.479962800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<xml><records/></xml>'\n"
     ]
    },
    {
     "data": {
      "text/plain": "b'<records/>'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path2 = './sources/template.xml'\n",
    "tree2 = etree.parse(path2)\n",
    "print(etree.tostring(tree2))\n",
    "records_node = tree2.xpath('.//records')[0]\n",
    "etree.tostring(records_node)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T14:06:17.127484700Z",
     "start_time": "2023-07-21T14:06:17.115483200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "'<xml><records><record><database name=\"我的Endnote库.enl\" path=\"D:\\\\03. 研究生资料\\\\01. 论文写作\\\\00. 核心期刊目录\\\\Endnote文件\\\\我的Endnote库.enl\">我的Endnote库.enl</database><source-app name=\"EndNote\" version=\"19.0\">EndNote</source-app><rec-number>221</rec-number><foreign-keys><key app=\"EN\" db-id=\"e29ar20dmt9sw9errfl55es39at9f5fx5azd\">221</key><key app=\"ENWeb\" db-id=\"\">0</key></foreign-keys><ref-type name=\"Thesis\">32</ref-type><contributors><authors><author><style face=\"normal\" font=\"default\" size=\"100%\">茹仙古丽·艾尔西丁（Roxangul Arxidin）</style></author></authors><tertiary-authors><author><style face=\"normal\" font=\"default\" size=\"100%\">严传波,</style></author></tertiary-authors></contributors><titles><title><style face=\"normal\" font=\"default\" size=\"100%\">基于深度学习的肝囊型包虫病CT图像分类方法研究</style></title></titles><keywords><keyword><style face=\"normal\" font=\"default\" size=\"100%\">深度学习</style></keyword><keyword><style face=\"normal\" font=\"default\" size=\"100%\">肝囊型包虫病CT图像</style></keyword><keyword><style face=\"normal\" font=\"default\" size=\"100%\">图像分类</style></keyword><keyword><style face=\"normal\" font=\"default\" size=\"100%\">计算机辅助诊断</style></keyword></keywords><dates><year><style face=\"normal\" font=\"default\" size=\"100%\">2020</style></year></dates><publisher><style face=\"normal\" font=\"default\" size=\"100%\">新疆医科大学</style></publisher><abstract><style face=\"normal\" font=\"default\" size=\"100%\">目的:探讨深度学习的卷积神经网络方法和技术在肝囊型包虫病CT图像分型中的应用,旨在为放射科医生的诊断决策提供具有实际参考价值的辅助信息,提高肝囊型包虫病诊断的准确率和效率。方法:(1)利用Python图像处理技术,对肝囊型包虫病CT图像进行预处理,包括归一化、数据增强。将图像分批次传入改进后的ResNet、LeNet和InceptionV3模型中进行训练。改进后的训练模型使用Relu和Softmax激活函数,ResNet模型使用SGD优化函数,LeNet和InceptionV3模型使用Adadelta优化函数。数据集按8:2划分为训练组和测试组,测试组采用交叉验证方法,学习率为0.005;训练模型导入分类模型中,使用0、1、2序列标注单囊型、多囊型和单发性囊肿三种类型后输出三维矩阵,根据矩阵的位置和比率判断图像的所属类型。(2)使用传统的MATLAB图像处理软件,手动截取病灶,对其进行归一化、去燥、增强预处理。提取灰度共生矩阵和灰度直方图的13维特征向量值,使用C4.5决策树和支持向量机分类器,通过十折交叉验证法对提取特征向量值后的图像进行分类。(3)两种方法均使用准确率、敏感性、特异性评估指标对各分类模型性能进行评估。结果:(1)深度学习的卷积神经网络方法:三种肝包虫病CT图像在ResNet、LeNet、InceptionV3训练模型中的最佳平均训练准确率分别为93.22%、76.55%、90.75%。分类模型中的准确率分别为0.93、0.68、0.81,敏感性为0.92、0.58、0.76,特异性为0.94、0.78、0.86。(2)传统方法:两种特征向量值在C4.5决策树分类器中的分类准确率分别为87.6%、89.31%;在支持向量机分类器中的分类准确率分别为68.34%、81.93%。C4.5决策树分类器的准确率、敏感性、特异性分别为0.92、0.89、0.94;支持向量机分类器的分别为0.87、0.83、0.91。结论:(1)深度学习的卷积神经网络方法:ResNet模型的训练、图像特征学习效率和各评估指标优于LeNet和InceptionV3模型;三种分类模型对多囊型肝包虫病CT图像的分类效果最好,其次是单囊型;综合考虑肝囊型包虫病CT图像的分型情况,ResNet模型最适合用于三种CT图像的准确分类;(2)传统方法:C4.5决策树分类器的分类效果比支持向量机分类器的效果好,灰度直方图特征向量值的效率最佳。C4.5决策树分类器使用灰度直方图特征向量值更适合于肝包虫病CT图像的分型。(3)深度学习的卷积神经网络模型对肝囊型包虫病CT图像分型较传统方法具有可行性和合理性。本研究结果可以为放射科医生对肝包虫病的诊断提供有价值的参考意见,为开发面向临床的肝包虫病计算机辅助诊断系统奠定了基础。</style></abstract><work-type><style face=\"normal\" font=\"default\" size=\"100%\">硕士</style></work-type><urls><pdf-urls><url>internal-pdf://2443169046/基于深度学习的肝囊型包虫病CT图像分类方法研究.pdf</url></pdf-urls></urls><electronic-resource-num><style face=\"normal\" font=\"default\" size=\"100%\">10.27433/d.cnki.gxyku.2020.000858</style></electronic-resource-num><remote-database-provider><style face=\"normal\" font=\"default\" size=\"100%\">Cnki</style></remote-database-provider></record></records></xml>'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 插入节点\n",
    "records_node.append(a)\n",
    "# 输出插入后的XML内容\n",
    "resulting_xml = etree.tostring(tree2, encoding='unicode')\n",
    "resulting_xml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T14:07:28.724458Z",
     "start_time": "2023-07-21T14:07:28.708504Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "temp = '<?xml version=\"1.0\" encoding=\"UTF-8\" ?>'\n",
    "final_xml_text = temp + resulting_xml\n",
    "with open('./sources/test.xml', 'w', 1, 'utf-8') as f:\n",
    "    f.write(final_xml_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T14:08:38.557430400Z",
     "start_time": "2023-07-21T14:08:38.543441700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "'<xml><records><record><database name=\"我的Endnote库.enl\" path=\"D:\\\\03. 研究生资料\\\\01. 论文写作\\\\00. 核心期刊目录\\\\Endnote文件\\\\我的Endnote库.enl\">我的Endnote库.enl</database><source-app name=\"EndNote\" version=\"19.0\">EndNote</source-app><rec-number>221</rec-number><foreign-keys><key app=\"EN\" db-id=\"e29ar20dmt9sw9errfl55es39at9f5fx5azd\">221</key><key app=\"ENWeb\" db-id=\"\">0</key></foreign-keys><ref-type name=\"Thesis\">32</ref-type><contributors><authors><author><style face=\"normal\" font=\"default\" size=\"100%\">茹仙古丽·艾尔西丁（Roxangul Arxidin）</style></author></authors><tertiary-authors><author><style face=\"normal\" font=\"default\" size=\"100%\">严传波,</style></author></tertiary-authors></contributors><titles><title><style face=\"normal\" font=\"default\" size=\"100%\">基于深度学习的肝囊型包虫病CT图像分类方法研究</style></title></titles><keywords><keyword><style face=\"normal\" font=\"default\" size=\"100%\">深度学习</style></keyword><keyword><style face=\"normal\" font=\"default\" size=\"100%\">肝囊型包虫病CT图像</style></keyword><keyword><style face=\"normal\" font=\"default\" size=\"100%\">图像分类</style></keyword><keyword><style face=\"normal\" font=\"default\" size=\"100%\">计算机辅助诊断</style></keyword></keywords><dates><year><style face=\"normal\" font=\"default\" size=\"100%\">2020</style></year></dates><publisher><style face=\"normal\" font=\"default\" size=\"100%\">新疆医科大学</style></publisher><abstract><style face=\"normal\" font=\"default\" size=\"100%\">目的:探讨深度学习的卷积神经网络方法和技术在肝囊型包虫病CT图像分型中的应用,旨在为放射科医生的诊断决策提供具有实际参考价值的辅助信息,提高肝囊型包虫病诊断的准确率和效率。方法:(1)利用Python图像处理技术,对肝囊型包虫病CT图像进行预处理,包括归一化、数据增强。将图像分批次传入改进后的ResNet、LeNet和InceptionV3模型中进行训练。改进后的训练模型使用Relu和Softmax激活函数,ResNet模型使用SGD优化函数,LeNet和InceptionV3模型使用Adadelta优化函数。数据集按8:2划分为训练组和测试组,测试组采用交叉验证方法,学习率为0.005;训练模型导入分类模型中,使用0、1、2序列标注单囊型、多囊型和单发性囊肿三种类型后输出三维矩阵,根据矩阵的位置和比率判断图像的所属类型。(2)使用传统的MATLAB图像处理软件,手动截取病灶,对其进行归一化、去燥、增强预处理。提取灰度共生矩阵和灰度直方图的13维特征向量值,使用C4.5决策树和支持向量机分类器,通过十折交叉验证法对提取特征向量值后的图像进行分类。(3)两种方法均使用准确率、敏感性、特异性评估指标对各分类模型性能进行评估。结果:(1)深度学习的卷积神经网络方法:三种肝包虫病CT图像在ResNet、LeNet、InceptionV3训练模型中的最佳平均训练准确率分别为93.22%、76.55%、90.75%。分类模型中的准确率分别为0.93、0.68、0.81,敏感性为0.92、0.58、0.76,特异性为0.94、0.78、0.86。(2)传统方法:两种特征向量值在C4.5决策树分类器中的分类准确率分别为87.6%、89.31%;在支持向量机分类器中的分类准确率分别为68.34%、81.93%。C4.5决策树分类器的准确率、敏感性、特异性分别为0.92、0.89、0.94;支持向量机分类器的分别为0.87、0.83、0.91。结论:(1)深度学习的卷积神经网络方法:ResNet模型的训练、图像特征学习效率和各评估指标优于LeNet和InceptionV3模型;三种分类模型对多囊型肝包虫病CT图像的分类效果最好,其次是单囊型;综合考虑肝囊型包虫病CT图像的分型情况,ResNet模型最适合用于三种CT图像的准确分类;(2)传统方法:C4.5决策树分类器的分类效果比支持向量机分类器的效果好,灰度直方图特征向量值的效率最佳。C4.5决策树分类器使用灰度直方图特征向量值更适合于肝包虫病CT图像的分型。(3)深度学习的卷积神经网络模型对肝囊型包虫病CT图像分型较传统方法具有可行性和合理性。本研究结果可以为放射科医生对肝包虫病的诊断提供有价值的参考意见,为开发面向临床的肝包虫病计算机辅助诊断系统奠定了基础。</style></abstract><work-type><style face=\"normal\" font=\"default\" size=\"100%\">硕士</style></work-type><urls><pdf-urls><url>internal-pdf://2443169046/基于深度学习的肝囊型包虫病CT图像分类方法研究.pdf</url></pdf-urls></urls><electronic-resource-num><style face=\"normal\" font=\"default\" size=\"100%\">10.27433/d.cnki.gxyku.2020.000858</style></electronic-resource-num><remote-database-provider><style face=\"normal\" font=\"default\" size=\"100%\">Cnki</style></remote-database-provider></record><record><database name=\"我的Endnote库.enl\" path=\"D:\\\\03. 研究生资料\\\\01. 论文写作\\\\00. 核心期刊目录\\\\Endnote文件\\\\我的Endnote库.enl\">我的Endnote库.enl</database><source-app name=\"EndNote\" version=\"19.0\">EndNote</source-app><rec-number>8</rec-number><foreign-keys><key app=\"EN\" db-id=\"e29ar20dmt9sw9errfl55es39at9f5fx5azd\">8</key><key app=\"ENWeb\" db-id=\"\">0</key></foreign-keys><ref-type name=\"Journal Article\">17</ref-type><contributors><authors><author><style face=\"normal\" font=\"default\" size=\"100%\">Anupindi, S. A.</style></author><author><style face=\"normal\" font=\"default\" size=\"100%\">Biko, D. M.</style></author><author><style face=\"normal\" font=\"default\" size=\"100%\">Ntoulia, A.</style></author><author><style face=\"normal\" font=\"default\" size=\"100%\">Poznick, L.</style></author><author><style face=\"normal\" font=\"default\" size=\"100%\">Morgan, T. A.</style></author><author><style face=\"normal\" font=\"default\" size=\"100%\">Darge, K.</style></author><author><style face=\"normal\" font=\"default\" size=\"100%\">Back, S. J.</style></author></authors></contributors><auth-address><style face=\"normal\" font=\"default\" size=\"100%\">From the Department of Radiology, The Children\\'s Hospital of Philadelphia, University of Pennsylvania, Perelman School of Medicine, 3401 Civic Center Blvd, Philadelphia, PA 19104.</style></auth-address><titles><title><style face=\"normal\" font=\"default\" size=\"100%\">Contrast-enhanced US Assessment of Focal Liver Lesions in Children</style></title><secondary-title><style face=\"normal\" font=\"default\" size=\"100%\">Radiographics</style></secondary-title></titles><periodical><full-title><style face=\"normal\" font=\"default\" size=\"100%\">Radiographics</style></full-title></periodical><pages><style face=\"normal\" font=\"default\" size=\"100%\">1632-1647</style></pages><volume><style face=\"normal\" font=\"default\" size=\"100%\">37</style></volume><number><style face=\"normal\" font=\"default\" size=\"100%\">6</style></number><keywords><keyword><style face=\"normal\" font=\"default\" size=\"100%\">Child</style></keyword><keyword><style face=\"normal\" font=\"default\" size=\"100%\">*Contrast Media</style></keyword><keyword><style face=\"normal\" font=\"default\" size=\"100%\">Diagnosis, Differential</style></keyword><keyword><style face=\"normal\" font=\"default\" size=\"100%\">Humans</style></keyword><keyword><style face=\"normal\" font=\"default\" size=\"100%\">Liver Diseases/*diagnostic imaging</style></keyword><keyword><style face=\"normal\" font=\"default\" size=\"100%\">Ultrasonography/*methods</style></keyword></keywords><dates><year><style face=\"normal\" font=\"default\" size=\"100%\">2017</style></year><pub-dates><date><style face=\"normal\" font=\"default\" size=\"100%\">Oct</style></date></pub-dates></dates><isbn><style face=\"normal\" font=\"default\" size=\"100%\">0271-5333</style></isbn><accession-num><style face=\"normal\" font=\"default\" size=\"100%\">29019750</style></accession-num><abstract><style face=\"normal\" font=\"default\" size=\"100%\">Ultrasonography (US) is often the first line of imaging for the examination of children suspected of having liver lesions. However, gray-scale US with color Doppler imaging has limitations. The use of US contrast agents has recently been approved by the U.S. Food and Drug Administration (FDA). Compared with other imaging modalities, contrast material-enhanced US (CEUS) enables the assessment of contrast enhancement patterns with a higher temporal resolution and is therefore becoming a valuable alternative imaging technique. CEUS is advantageous owing to its high safety profile; lower cost, compared with the costs of conventional contrast-enhanced computed tomographic and magnetic resonance imaging examinations; reliability; and reproducibility. Furthermore, US examinations obviate the use of sedation, ionizing radiation, and iodinated or gadolinium-based contrast agents. All of these are desirable attributes for an imaging examination for children, the most vulnerable of patients. Focal liver lesions in children are commonly discovered incidentally, and this can pose a dilemma in terms of diagnosis and management. Owing to the FDA\\'s recent approval of the use of a specific US contrast agent for evaluation of focal liver lesions in pediatric patients, CEUS can now be used as a problem-solving tool that complements conventional imaging examinations and aids in the follow-up of lesions. The temporal resolution with CEUS enables US images to readily depict the real-time internal vascularity of a lesion. The characterization of a lesion during different phases of enhancement improves diagnostic confidence and treatment. In this article, the authors review the composition, physiologic properties, and safety profile of CEUS; describe the technique for performing CEUS; and highlight the utility of this examination in the assessment of common focal liver lesions in children. Online supplemental material is available for this article. (©)RSNA, 2017.</style></abstract><notes><style face=\"normal\" font=\"default\" size=\"100%\">1527-1323&#13;Anupindi, Sudha A&#13;Biko, David M&#13;Ntoulia, Aikaterini&#13;Poznick, Laura&#13;Morgan, Trudy A&#13;Darge, Kassa&#13;Back, Susan J&#13;Journal Article&#13;Review&#13;United States&#13;2017/10/12&#13;Radiographics. 2017 Oct;37(6):1632-1647. doi: 10.1148/rg.2017170073.</style></notes><urls><pdf-urls><url>internal-pdf://4057913250/anupindi2017.pdf</url></pdf-urls></urls><electronic-resource-num><style face=\"normal\" font=\"default\" size=\"100%\">10.1148/rg.2017170073</style></electronic-resource-num><remote-database-provider><style face=\"normal\" font=\"default\" size=\"100%\">NLM</style></remote-database-provider><language><style face=\"normal\" font=\"default\" size=\"100%\">eng</style></language></record></records></xml>'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path3 = './sources/test.xml'\n",
    "tree3 = etree.parse(path3)\n",
    "records_node3 = tree3.xpath('.//records')[0]\n",
    "records_node3.append(findings[0])\n",
    "resulting_xml3 = etree.tostring(tree3, encoding='unicode')\n",
    "resulting_xml3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T14:17:12.705377Z",
     "start_time": "2023-07-21T14:17:12.644882500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "temp = '<?xml version=\"1.0\" encoding=\"UTF-8\" ?>'\n",
    "final_xml_text3 = temp + resulting_xml3\n",
    "with open('./sources/test2.xml', 'w', 1, 'utf-8') as f:\n",
    "    f.write(final_xml_text3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T14:18:17.083185200Z",
     "start_time": "2023-07-21T14:18:17.070219800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "path4 = './sources/乱码中文.xml'\n",
    "tree4 = etree.parse(path4)\n",
    "records_node4 = tree4.xpath('.//records')[0]\n",
    "records_node4.append(a)\n",
    "resulting_xml4 = etree.tostring(tree4, encoding='unicode')\n",
    "temp = '<?xml version=\"1.0\" encoding=\"UTF-8\" ?>'\n",
    "final_xml_text4 = temp + resulting_xml4\n",
    "with open('./sources/test4.xml', 'w', 1, 'utf-8') as f:\n",
    "    f.write(final_xml_text4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T14:27:20.640039300Z",
     "start_time": "2023-07-21T14:27:20.633058400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
